Kind of a clusterfuck of a contest.  Server was down as soon as the contest started, so I was stuck refreshing for about an hour.  I was also trying to submit my problem 2 for a long time, but the servers were fucked, so it looked like my submissions weren't going through.

In actuality, I think they were going through, but because they were WA instead of AC, nothing was happening (and the server/webpage were fucked so there was no UI feedback and it just looked like dead servers).

Most frustratingly, I believe my solutions for problem 2 were *correct* and the anticipated solutions for problem 2 were actually *incorrect*.  I outlined the reasons here: https://twitter.com/010010110000110/status/1425891922854428681

1. the expected answer uses `splitlines` which for some reason truncates ending newlines, which gives incorrect answers for any inputs where one of the inputs has a trailing newline.  There were such inputs in the testcases, so my code was failing, but Codex's incorrect code passed.  (See: my code `b.py` vs Codex's code `b_openai.py`, and look at the testcase `print(diff_files('\nz\ncW\nFe1by\n6X5\n\nsqFzv\nb', 'S\nxb3\n1\nlfJ1\nt9sqW\nUUUZE\n\n\n\nw\nqjT\ngGVBL\n\n'))`)
2. the recommended library, `difflib`, doesn't return minimal edit distances.  (It says as much in the docs: "This does not yield minimal edit sequences, but does tend to yield matches that “look right” to people." and "Note that Differ-generated deltas make no claim to be minimal diffs.")  The actual solution would be to use LCS.  There were testcases for which difflib's output differed from the minimal output, and so Codex's incorrect code passed.  (See: `b_lcs.py` vs Codex's code `b_openai.py` and look at the testcase `print(diff_files('\n1Eqml\nGsWG\n\n7aCdG\n\n6OTK\nr\na5o\ns\nXsNOj\nr\nSL\n\n\nLP\ny\nwqjH\nR\nT', 'DUq\n\n\n\n3HWhe\n'))`)